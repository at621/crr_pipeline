{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e5f6b6-0505-4698-a4ad-d4de2a08070c",
   "metadata": {},
   "source": [
    "# Multi-Strategy Document Retrieval and Evaluation System\n",
    "\n",
    "## Objective\n",
    "Build a Python/LangChain system that compares four different document retrieval strategies against a golden source benchmark, evaluating their accuracy and cost-effectiveness for question-answering tasks.\n",
    "\n",
    "## Input Requirements\n",
    "\n",
    "### 1. Document Dataset (Excel)\n",
    "**File:** `document_dataset.xlsx`\n",
    "| TOC_Number | Text |\n",
    "|------------|------|\n",
    "| 1.1 | Introduction to machine learning fundamentals |\n",
    "| 1.2 | Supervised learning algorithms and applications |\n",
    "| ... | ... |\n",
    "\n",
    "### 2. Golden Source Questions (Excel)\n",
    "**File:** `golden_source.xlsx`\n",
    "| Question_ID | Question_Text | TOC_1 | TOC_2 | TOC_3 | TOC_4 | TOC_5 |\n",
    "|-------------|--------------|--------|--------|--------|--------|--------|\n",
    "| Q1 | How do I evaluate my ML model? | 2.2 | 1.2 | 2.1 | 1.3 | 3.1 |\n",
    "| Q2 | What are neural network types? | 3.1 | 3.2 | 1.1 | 1.2 | 2.1 |\n",
    "| ... | ... | ... | ... | ... | ... | ... |\n",
    "| Q10 | ... | ... | ... | ... | ... | ... |\n",
    "\n",
    "### 3. Category Definitions\n",
    "- **Category_1** (Topic): List of valid categories to be provided\n",
    "- **Category_2** (Level): List of valid categories to be provided\n",
    "\n",
    "## System Components\n",
    "\n",
    "### 1. Data Preprocessing\n",
    "\n",
    "#### 1.1 Document Categorization\n",
    "- For each row in the document dataset:\n",
    "  - Automatically assign Category_1 (Topic) based on text content\n",
    "  - Automatically assign Category_2 (Level) based on text complexity\n",
    "- Methods:\n",
    "  - Zero-shot classification using LLM\n",
    "  - Or embedding similarity to category descriptions\n",
    "  - Or keyword/rule-based assignment\n",
    "\n",
    "#### 1.2 Processed Dataset Structure\n",
    "After categorization, create:\n",
    "| TOC_Number | Text | Category_1 | Category_2 |\n",
    "|------------|------|------------|------------|\n",
    "| 1.1 | Introduction to machine learning fundamentals | Fundamentals | Beginner |\n",
    "| 1.2 | Supervised learning algorithms and applications | Algorithms | Intermediate |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "#### 1.3 Embedding Generation\n",
    "- Create embeddings for all document texts (OpenAI/Claude)\n",
    "- Store embeddings with metadata\n",
    "\n",
    "### 2. Question Processing\n",
    "- Embed each incoming question\n",
    "- Categorize questions into both category types using same method as documents\n",
    "\n",
    "### 3. Four Retrieval Strategies\n",
    "\n",
    "#### Strategy A: Pure Embedding Similarity\n",
    "- Compute cosine similarity between question and document embeddings\n",
    "- Return top 5 most similar documents\n",
    "- Cost: Embedding lookup only\n",
    "\n",
    "#### Strategy B: Category Filtering\n",
    "- Filter documents matching question's categories\n",
    "- Return up to 5 matches (by TOC order)\n",
    "- Cost: Metadata query only\n",
    "\n",
    "#### Strategy C: Hybrid (Categories + Similarity)\n",
    "- Filter by categories first\n",
    "- Rank filtered results by embedding similarity\n",
    "- Return top 5\n",
    "- Cost: Filtering + embedding lookup\n",
    "\n",
    "#### Strategy D: Full Context with Cache\n",
    "- Load entire document into LLM context\n",
    "- Use prompt caching for cost reduction\n",
    "- Let LLM select 5 most relevant sections\n",
    "- Cost: Full LLM inference (reduced with caching)\n",
    "\n",
    "### 4. Evaluation Metrics\n",
    "For each question and strategy, calculate:\n",
    "- **Matches**: Number of retrieved TOCs that appear in golden source\n",
    "- **Precision@5**: Matches / 5\n",
    "- **Cost**: Based on API calls (embeddings, LLM tokens)\n",
    "- **Latency**: Time to retrieve results\n",
    "\n",
    "## Implementation Steps\n",
    "\n",
    "```python\n",
    "# Pseudo-code structure\n",
    "class DocumentCategorizer:\n",
    "    def __init__(self, category_1_list, category_2_list, llm_model):\n",
    "        self.categories_1 = category_1_list\n",
    "        self.categories_2 = category_2_list\n",
    "        self.llm = llm_model\n",
    "        \n",
    "    def categorize_text(self, text):\n",
    "        # Return (category_1, category_2)\n",
    "        # Option 1: LLM-based categorization\n",
    "        prompt = f\"\"\"\n",
    "        Categorize this text:\n",
    "        \"{text}\"\n",
    "        \n",
    "        Category 1 options: {self.categories_1}\n",
    "        Category 2 options: {self.categories_2}\n",
    "        \n",
    "        Return: (category_1, category_2)\n",
    "        \"\"\"\n",
    "        return self.llm.predict(prompt)\n",
    "        \n",
    "    def categorize_dataset(self, document_df):\n",
    "        # Add category columns to dataframe\n",
    "        for idx, row in document_df.iterrows():\n",
    "            cat1, cat2 = self.categorize_text(row['Text'])\n",
    "            document_df.loc[idx, 'Category_1'] = cat1\n",
    "            document_df.loc[idx, 'Category_2'] = cat2\n",
    "        return document_df\n",
    "\n",
    "class DocumentRetriever:\n",
    "    def __init__(self, categorized_document_df, embedding_model):\n",
    "        # Initialize embeddings and categories\n",
    "        \n",
    "    def categorize_question(self, question):\n",
    "        # Return (category_1, category_2)\n",
    "        \n",
    "    def retrieve_by_embedding(self, question, k=5):\n",
    "        # Strategy A implementation\n",
    "        \n",
    "    def retrieve_by_category(self, question, k=5):\n",
    "        # Strategy B implementation\n",
    "        \n",
    "    def retrieve_hybrid(self, question, k=5):\n",
    "        # Strategy C implementation\n",
    "        \n",
    "    def retrieve_full_context(self, question, k=5):\n",
    "        # Strategy D implementation\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, golden_source_df):\n",
    "        # Load golden source\n",
    "        \n",
    "    def evaluate_strategy(self, strategy_results, question_id):\n",
    "        # Calculate precision and matches\n",
    "        \n",
    "    def generate_report(self, all_results):\n",
    "        # Create summary and detailed tables\n",
    "```\n",
    "\n",
    "## Expected Outputs\n",
    "\n",
    "### 1. Categorized Document Dataset (Excel)\n",
    "**File:** `document_dataset_categorized.xlsx`\n",
    "- Original columns plus Category_1 and Category_2\n",
    "- Export for verification and manual correction if needed\n",
    "\n",
    "### 2. Summary Table\n",
    "\n",
    "| Strategy | Avg Precision | Total Cost | Avg Latency | Best For |\n",
    "|----------|---------------|------------|-------------|----------|\n",
    "| A: Embedding | 0.62 | 0.0010 | 50ms | Semantic search |\n",
    "| B: Categories | 0.48 | 0.0000 | 10ms | Quick filtering |\n",
    "| C: Hybrid | 0.74 |  0.0010 | 60ms | Balanced approach |\n",
    "| D: Full Context | 0.88 | 0.0500 | 500ms | High accuracy |\n",
    "\n",
    "### 3. Detailed Results (Excel Export)\n",
    "- **Sheet 1**: Summary statistics\n",
    "- **Sheet 2**: Per-question results for all strategies\n",
    "- **Sheet 3**: Cost breakdown by component\n",
    "- **Sheet 4**: Retrieved TOCs vs Golden TOCs comparison\n",
    "- **Sheet 5**: Categorized documents\n",
    "\n",
    "### 4. Cost Breakdown Example\n",
    "```\n",
    "Initial Setup:\n",
    "- Document categorization: 100 docs × $0.001 = $0.10 (one-time)\n",
    "- Document embeddings: 100 docs × $0.0001 = $0.01 (one-time)\n",
    "\n",
    "Per-Question Costs:\n",
    "- Question categorization: $0.001\n",
    "- Strategy A: $0.0001 (embedding lookup)\n",
    "- Strategy B: $0.0000 (metadata only)\n",
    "- Strategy C: $0.0001 (filtering + embedding)\n",
    "- Strategy D: $0.005 (full context) or $0.0005 (cached)\n",
    "```\n",
    "\n",
    "## Technical Specifications\n",
    "\n",
    "### Required Libraries\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import openpyxl\n",
    "from tqdm import tqdm  # For progress bars during categorization\n",
    "```\n",
    "\n",
    "### Configuration Parameters\n",
    "```python\n",
    "config = {\n",
    "    \"embedding_model\": \"text-embedding-ada-002\",\n",
    "    \"llm_model\": \"gpt-4\",\n",
    "    \"retrieval_k\": 5,\n",
    "    \"categories_1\": [\"Fundamentals\", \"Algorithms\", \"Data Processing\", \"Advanced Topics\"],\n",
    "    \"categories_2\": [\"Beginner\", \"Intermediate\", \"Advanced\", \"Expert\"],\n",
    "    \"cost_per_embedding\": 0.0001,\n",
    "    \"cost_per_1k_tokens\": 0.03,\n",
    "    \"use_cache\": True,\n",
    "    \"categorization_method\": \"llm\"  # Options: \"llm\", \"embedding\", \"keyword\"\n",
    "}\n",
    "```\n",
    "\n",
    "### Usage Example\n",
    "```python\n",
    "# Step 1: Load and categorize documents\n",
    "documents_df = pd.read_excel(\"document_dataset.xlsx\")\n",
    "golden_df = pd.read_excel(\"golden_source.xlsx\")\n",
    "\n",
    "categorizer = DocumentCategorizer(\n",
    "    config[\"categories_1\"], \n",
    "    config[\"categories_2\"], \n",
    "    ChatOpenAI(model=config[\"llm_model\"])\n",
    ")\n",
    "\n",
    "print(\"Categorizing documents...\")\n",
    "categorized_df = categorizer.categorize_dataset(documents_df)\n",
    "categorized_df.to_excel(\"document_dataset_categorized.xlsx\", index=False)\n",
    "\n",
    "# Step 2: Initialize retrieval system\n",
    "retriever = DocumentRetriever(categorized_df, config)\n",
    "evaluator = Evaluator(golden_df)\n",
    "\n",
    "# Step 3: Run evaluation\n",
    "results = {}\n",
    "for idx, row in golden_df.iterrows():\n",
    "    question_id = row['Question_ID']\n",
    "    question = row['Question_Text']\n",
    "    \n",
    "    results[question_id] = {\n",
    "        'A': retriever.retrieve_by_embedding(question),\n",
    "        'B': retriever.retrieve_by_category(question),\n",
    "        'C': retriever.retrieve_hybrid(question),\n",
    "        'D': retriever.retrieve_full_context(question)\n",
    "    }\n",
    "\n",
    "# Step 4: Generate report\n",
    "evaluator.generate_report(results)\n",
    "```\n",
    "\n",
    "## Deliverables\n",
    "1. Categorized document dataset (Excel file)\n",
    "2. Working Python script with:\n",
    "   - Automatic document categorization\n",
    "   - Four retrieval strategies\n",
    "   - Evaluation framework\n",
    "3. Excel report with comprehensive evaluation metrics\n",
    "4. Cost analysis including:\n",
    "   - One-time setup costs (categorization, embeddings)\n",
    "   - Per-query costs for each strategy\n",
    "5. Recommendations based on accuracy/cost tradeoffs\n",
    "\n",
    "## Notes\n",
    "- The categorization step is crucial for Strategy B and C\n",
    "- Consider manual verification of categories for critical documents\n",
    "- Category definitions should be clear and mutually exclusive\n",
    "- Save categorized dataset for reuse in future experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60df3c7-3c7d-4a2f-acc8-a42b7eda642e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4.1-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75387c15-1e7e-4b99-82b2-b08dcbf0d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openpyxl\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# --- Configuration ---\n",
    "load_dotenv()\n",
    "\n",
    "config = {\n",
    "    \"embedding_model\": \"text-embedding-3-small\",\n",
    "    \"llm_model\": \"gpt-4-turbo\",\n",
    "    \"retrieval_k\": 5,\n",
    "    \"categories_1\": [\"Fundamentals\", \"Algorithms\", \"Data Processing\", \"Advanced Topics\", \"Evaluation\"],\n",
    "    \"categories_2\": [\"Beginner\", \"Intermediate\", \"Advanced\", \"Expert\"],\n",
    "    \"cost_embedding_per_1m_tokens\": 0.02,\n",
    "    \"cost_llm_input_per_1m_tokens\": 5.00,\n",
    "    \"cost_llm_output_per_1m_tokens\": 15.00,\n",
    "    \"use_cache\": True,\n",
    "}\n",
    "\n",
    "# --- Helper Functions & Setup ---\n",
    "\n",
    "def create_dummy_files():\n",
    "    \"\"\"Creates dummy Excel files for demonstration if they don't exist.\"\"\"\n",
    "    doc_file = \"document_dataset.xlsx\"\n",
    "    golden_file = \"golden_source.xlsx\"\n",
    "    if not os.path.exists(doc_file):\n",
    "        print(f\"Creating dummy file: {doc_file}\")\n",
    "        pd.DataFrame({\n",
    "            \"TOC_Number\": [\"1.1\", \"1.2\", \"1.3\", \"2.1\", \"2.2\", \"2.3\", \"3.1\", \"3.2\", \"3.3\", \"4.1\"],\n",
    "            \"Text\": [\n",
    "                \"Introduction to machine learning, covering basic concepts like variables and data types.\",\n",
    "                \"Exploring supervised learning algorithms, including linear regression and logistic regression.\",\n",
    "                \"An overview of unsupervised learning techniques such as k-means clustering.\",\n",
    "                \"Deep dive into data preprocessing: handling missing values, scaling features.\",\n",
    "                \"Methods for model evaluation: confusion matrix, precision, recall, and F1-score.\",\n",
    "                \"Feature engineering strategies to improve model performance.\",\n",
    "                \"A look at neural networks and their fundamental architecture.\",\n",
    "                \"Advanced neural network types: Convolutional Neural Networks (CNNs) for images.\",\n",
    "                \"Recurrent Neural Networks (RNNs) for sequence data.\",\n",
    "                \"Understanding transfer learning and fine-tuning pre-trained models.\"\n",
    "            ]\n",
    "        }).to_excel(doc_file, index=False)\n",
    "    if not os.path.exists(golden_file):\n",
    "        print(f\"Creating dummy file: {golden_file}\")\n",
    "        pd.DataFrame({\n",
    "            \"Question_ID\": [f\"Q{i}\" for i in range(1, 6)],\n",
    "            \"Question_Text\": [\n",
    "                \"How do I evaluate my machine learning model?\", \"What are the main types of neural networks?\",\n",
    "                \"How should I start learning about ML?\", \"What is the difference between supervised and unsupervised learning?\",\n",
    "                \"How to prepare data for a model?\"\n",
    "            ],\n",
    "            \"TOC_1\": [\"2.2\", \"3.2\", \"1.1\", \"1.2\", \"2.1\"], \"TOC_2\": [\"2.3\", \"3.1\", \"1.2\", \"1.3\", \"2.3\"],\n",
    "            \"TOC_3\": [\"1.2\", \"3.3\", \"2.1\", \"3.1\", \"4.1\"], \"TOC_4\": [\"4.1\", \"4.1\", \"1.3\", \"2.2\", \"1.2\"],\n",
    "            \"TOC_5\": [\"1.1\", \"1.1\", \"3.1\", \"2.1\", \"3.2\"],\n",
    "        }).to_excel(golden_file, index=False)\n",
    "\n",
    "# --- System Components ---\n",
    "\n",
    "class CostTracker:\n",
    "    def __init__(self, config):\n",
    "        self.config, self.total_cost, self.cost_breakdown = config, 0, {\n",
    "            \"setup_categorization\": 0, \"setup_embedding\": 0, \"query_categorization\": 0,\n",
    "            \"query_embedding\": 0, \"query_llm_context\": 0\n",
    "        }\n",
    "    def _calculate_cost(self, tokens, type):\n",
    "        if type == \"embedding\": return (tokens / 1_000_000) * self.config['cost_embedding_per_1m_tokens']\n",
    "        if type == \"llm_input\": return (tokens / 1_000_000) * self.config['cost_llm_input_per_1m_tokens']\n",
    "        if type == \"llm_output\": return (tokens / 1_000_000) * self.config['cost_llm_output_per_1m_tokens']\n",
    "        return 0\n",
    "        \n",
    "    def add_cost(self, tokens, type, component):\n",
    "        cost = self._calculate_cost(tokens, type)\n",
    "        self.total_cost += cost\n",
    "        if component in self.cost_breakdown: self.cost_breakdown[component] += cost\n",
    "        return cost\n",
    "        \n",
    "    def get_summary(self): return {\"total_cost\": self.total_cost, \"breakdown\": self.cost_breakdown}\n",
    "\n",
    "class DocumentCategorizer:\n",
    "    def __init__(self, category_1_list, category_2_list, llm, cost_tracker):\n",
    "        self.llm, self.cost_tracker = llm, cost_tracker\n",
    "        class Categories(BaseModel):\n",
    "            category_1: str = Field(description=f\"The topic from the list: {category_1_list}\")\n",
    "            category_2: str = Field(description=f\"The level from the list: {category_2_list}\")\n",
    "        self.parser = PydanticOutputParser(pydantic_object=Categories)\n",
    "        self.prompt = PromptTemplate(\n",
    "            template=\"Analyze the text and assign categories.\\n{format_instructions}\\nText: \\\"{text}\\\"\",\n",
    "            input_variables=[\"text\"], partial_variables={\"format_instructions\": self.parser.get_format_instructions()},\n",
    "        )\n",
    "        self.chain = self.prompt | self.llm | self.parser\n",
    "        \n",
    "    def categorize_text(self, text: str):\n",
    "        try:\n",
    "            input_tokens, result = len(text) // 4, self.chain.invoke({\"text\": text})\n",
    "            output_tokens = len(str(result)) // 4\n",
    "            self.cost_tracker.add_cost(input_tokens, \"llm_input\", \"setup_categorization\")\n",
    "            self.cost_tracker.add_cost(output_tokens, \"llm_output\", \"setup_categorization\")\n",
    "            return result.category_1, result.category_2\n",
    "        except Exception as e: return \"Uncategorized\", \"Uncategorized\"\n",
    "            \n",
    "    def categorize_dataset(self, df: pd.DataFrame):\n",
    "        cats = [self.categorize_text(row['Text']) for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Categorizing Documents\")]\n",
    "        return pd.concat([df, pd.DataFrame(cats, columns=[\"Category_1\", \"Category_2\"])], axis=1)\n",
    "\n",
    "class DocumentRetriever:\n",
    "    def __init__(self, df, config, cost_tracker):\n",
    "        self.df, self.config, self.cost_tracker, self.llm_cache = df.copy(), config, cost_tracker, {}\n",
    "        self.embedding_model = OpenAIEmbeddings(model=config[\"embedding_model\"])\n",
    "        self.llm = ChatOpenAI(model=config[\"llm_model\"], temperature=0)\n",
    "        self.categorizer = DocumentCategorizer(config[\"categories_1\"], config[\"categories_2\"], self.llm, cost_tracker)\n",
    "        print(\"Generating document embeddings...\")\n",
    "        texts, total_tokens = self.df['Text'].tolist(), sum(len(t)//4 for t in self.df['Text'])\n",
    "        self.cost_tracker.add_cost(total_tokens, 'embedding', 'setup_embedding')\n",
    "        self.df['embedding'] = self.embedding_model.embed_documents(texts)\n",
    "        \n",
    "    def _categorize_question(self, question, question_id):\n",
    "        if hasattr(self, '_cat_cache') and question_id in self._cat_cache: return self._cat_cache[question_id]\n",
    "        input_tokens, (cat1, cat2) = len(question)//4, self.categorizer.categorize_text(question)\n",
    "        output_tokens = len(cat1)//4 + len(cat2)//4\n",
    "        self.cost_tracker.add_cost(input_tokens, 'llm_input', 'query_categorization')\n",
    "        self.cost_tracker.add_cost(output_tokens, 'llm_output', 'query_categorization')\n",
    "        if not hasattr(self, '_cat_cache'): self._cat_cache = {}\n",
    "        self._cat_cache[question_id] = (cat1, cat2)\n",
    "        return cat1, cat2\n",
    "        \n",
    "    def retrieve(self, s_name, question, k, q_id):\n",
    "        start = time.time()\n",
    "        if s_name == 'A': tocs, cost = self.retrieve_by_embedding(question, k)\n",
    "        elif s_name == 'B': tocs, cost = self.retrieve_by_category(question, k, q_id)\n",
    "        elif s_name == 'C': tocs, cost = self.retrieve_hybrid(question, k, q_id)\n",
    "        elif s_name == 'D': tocs, cost = self.retrieve_full_context(question, k)\n",
    "        else: raise ValueError(f\"Unknown strategy: {s_name}\")\n",
    "        return tocs, (time.time() - start) * 1000, cost\n",
    "        \n",
    "    def retrieve_by_embedding(self, question, k):\n",
    "        q_emb = self.embedding_model.embed_query(question)\n",
    "        cost = self.cost_tracker.add_cost(len(question)//4, \"embedding\", \"query_embedding\")\n",
    "        sims = cosine_similarity([q_emb], np.array(self.df['embedding'].tolist()))[0]\n",
    "        return self.df.iloc[np.argsort(sims)[::-1][:k]]['TOC_Number'].tolist(), cost\n",
    "        \n",
    "    def retrieve_by_category(self, question, k, q_id):\n",
    "        cat1, cat2 = self._categorize_question(question, q_id)\n",
    "        df = self.df[(self.df['Category_1'] == cat1) & (self.df['Category_2'] == cat2)]\n",
    "        if df.empty: df = self.df[self.df['Category_1'] == cat1]\n",
    "        return df['TOC_Number'].head(k).tolist(), 0\n",
    "        \n",
    "    def retrieve_hybrid(self, question, k, q_id):\n",
    "        cost = self.cost_tracker.add_cost(len(question)//4, \"embedding\", \"query_embedding\")\n",
    "        cat1, cat2 = self._categorize_question(question, q_id)\n",
    "        # --- THIS IS THE CORRECTED LINE ---\n",
    "        df = pd.concat([\n",
    "            self.df[(self.df['Category_1']==cat1)&(self.df['Category_2']==cat2)], \n",
    "            self.df[self.df['Category_1']==cat1]\n",
    "        ]).drop_duplicates(subset=['TOC_Number']).reset_index(drop=True)\n",
    "        # --- END OF CORRECTION ---\n",
    "        if df.empty: return [], cost\n",
    "        q_emb = self.embedding_model.embed_query(question)\n",
    "        df['sim'] = cosine_similarity([q_emb], np.array(df['embedding'].tolist()))[0]\n",
    "        return df.sort_values('sim', ascending=False).head(k)['TOC_Number'].tolist(), cost\n",
    "        \n",
    "    def retrieve_full_context(self, question, k):\n",
    "        if self.config['use_cache'] and question in self.llm_cache: return self.llm_cache[question][0], 0\n",
    "        context_str = \"\\n\".join([f\"TOC {row['TOC_Number']}: {row['Text']}\" for _, row in self.df.iterrows()])\n",
    "        prompt = f\"\"\"Given the document context below, identify the TOP {k} `TOC_Number`s most relevant to the user's question. Return only a comma-separated list of TOC numbers (e.g., 1.1, 2.3, 3.2).\n",
    "CONTEXT:\n",
    "---\n",
    "{context_str}\n",
    "---\n",
    "QUESTION: \"{question}\"\n",
    "Relevant TOC_Numbers:\n",
    "\"\"\"\n",
    "        res = self.llm.invoke(prompt).content.strip()\n",
    "        tocs = [t.strip() for t in res.split(',')]\n",
    "        cost = self.cost_tracker.add_cost(len(prompt)//4, 'llm_input', 'query_llm_context') + \\\n",
    "               self.cost_tracker.add_cost(len(res)//4, 'llm_output', 'query_llm_context')\n",
    "        if self.config['use_cache']: self.llm_cache[question] = (tocs, cost)\n",
    "        return tocs, cost\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(self, golden_source_df, k):\n",
    "        self.k = k\n",
    "        self.golden_df = golden_source_df\n",
    "        toc_cols = [f'TOC_{i}' for i in range(1, 6)]\n",
    "        self.golden_map = {row['Question_ID']: set(row[toc_cols].astype(str).values) for _, row in self.golden_df.iterrows()}\n",
    "            \n",
    "    def evaluate_run(self, retrieved_tocs, question_id):\n",
    "        golden_tocs = self.golden_map.get(question_id, set())\n",
    "        matches = len(set(retrieved_tocs).intersection(golden_tocs))\n",
    "        precision = matches / self.k if self.k > 0 else 0\n",
    "        return {'matches': matches, 'precision': precision, 'retrieved_tocs': \", \".join(map(str, retrieved_tocs)), 'golden_tocs': \", \".join(map(str, sorted(list(golden_tocs))))}\n",
    "\n",
    "    def generate_report(self, all_results, cost_tracker, categorized_df):\n",
    "        print(\"\\nGenerating final report...\")\n",
    "        report_filename = \"retrieval_evaluation_report.xlsx\"\n",
    "        strategy_map = {'A': 'A: Embedding', 'B': 'B: Categories', 'C': 'C: Hybrid', 'D': 'D: Full Context'}\n",
    "\n",
    "        # 1. Per-Question Accuracy Summary\n",
    "        per_q_summary_data = []\n",
    "        for q_id, q_results in all_results.items():\n",
    "            golden_tocs_set = self.golden_map.get(q_id, set())\n",
    "            golden_tocs_str = \", \".join(map(str, sorted(list(golden_tocs_set))))\n",
    "            for s_code, result in q_results.items():\n",
    "                if s_code == 'categorization_cost': continue\n",
    "                eval_metrics = self.evaluate_run(result['tocs'], q_id)\n",
    "                per_q_summary_data.append({\n",
    "                    'Question_ID': q_id,\n",
    "                    'Strategy': strategy_map[s_code],\n",
    "                    'Golden TOCs': golden_tocs_str,\n",
    "                    'Retrieved TOCs': eval_metrics['retrieved_tocs'],\n",
    "                    'Overlap %': f\"{eval_metrics['precision']:.0%}\"\n",
    "                })\n",
    "        per_q_summary_df = pd.DataFrame(per_q_summary_data)\n",
    "\n",
    "        # 2. Detailed Per-Question Metrics\n",
    "        detailed_metrics_data = []\n",
    "        for q_id, q_results in all_results.items():\n",
    "            row = {'Question_ID': q_id, 'Question_Text': self.golden_df[self.golden_df['Question_ID'] == q_id]['Question_Text'].iloc[0]}\n",
    "            q_cat_cost = q_results.get('categorization_cost', 0)\n",
    "            for s_code, result in q_results.items():\n",
    "                if s_code == 'categorization_cost': continue\n",
    "                eval_metrics = self.evaluate_run(result['tocs'], q_id)\n",
    "                final_cost = result['cost'] + (q_cat_cost if s_code in ['B', 'C'] else 0)\n",
    "                row[f'{s_code}_Matches'] = eval_metrics['matches']\n",
    "                row[f'{s_code}_Precision'] = eval_metrics['precision']\n",
    "                row[f'{s_code}_Latency(ms)'] = result['latency']\n",
    "                row[f'{s_code}_Cost($)'] = final_cost\n",
    "            detailed_metrics_data.append(row)\n",
    "        detailed_metrics_df = pd.DataFrame(detailed_metrics_data)\n",
    "\n",
    "        # 3. Strategy-Level Summary\n",
    "        summary_data = []\n",
    "        for s_code, s_name in strategy_map.items():\n",
    "            summary_data.append({\n",
    "                'Strategy': s_name,\n",
    "                'Avg Precision': f\"{detailed_metrics_df[f'{s_code}_Precision'].mean():.2%}\",\n",
    "                'Total Query Cost ($)': f\"{detailed_metrics_df[f'{s_code}_Cost($)'].sum():.6f}\",\n",
    "                'Avg Latency (ms)': f\"{detailed_metrics_df[f'{s_code}_Latency(ms)'].mean():.2f}\"\n",
    "            })\n",
    "        summary_df = pd.DataFrame(summary_data)\n",
    "        \n",
    "        # 4. Cost Breakdown\n",
    "        costs = cost_tracker.get_summary()\n",
    "        cost_df = pd.DataFrame({\n",
    "            'Component': [\n",
    "                'Setup: Document Categorization', 'Setup: Document Embeddings', '---',\n",
    "                'Total Query Costs (Aggregated)', '---', 'Total Estimated Cost (Setup + Query)'\n",
    "            ],\n",
    "            'Cost ($)': [\n",
    "                f\"{costs['breakdown']['setup_categorization']:.6f}\", f\"{costs['breakdown']['setup_embedding']:.6f}\", '---',\n",
    "                f\"{costs['total_cost'] - costs['breakdown']['setup_categorization'] - costs['breakdown']['setup_embedding']:.6f}\", '---',\n",
    "                f\"{costs['total_cost']:.6f}\"\n",
    "            ]\n",
    "        })\n",
    "\n",
    "        # 5. Write all DataFrames to a multi-sheet Excel file\n",
    "        with pd.ExcelWriter(report_filename, engine='openpyxl') as writer:\n",
    "            per_q_summary_df.to_excel(writer, sheet_name='Per-Question Accuracy Summary', index=False)\n",
    "            summary_df.to_excel(writer, sheet_name='Strategy-Level Summary', index=False)\n",
    "            detailed_metrics_df.to_excel(writer, sheet_name='Detailed Per-Question Metrics', index=False)\n",
    "            cost_df.to_excel(writer, sheet_name='Cost Breakdown', index=False)\n",
    "            categorized_df.drop(columns=['embedding'], errors='ignore').to_excel(\n",
    "                writer, sheet_name='Categorized Documents', index=False\n",
    "            )\n",
    "            \n",
    "        print(\"\\n--- Evaluation Report ---\")\n",
    "        print(\"Per-Question Accuracy Summary (Top 5 rows):\")\n",
    "        print(per_q_summary_df.head().to_string(index=False))\n",
    "        print(\"\\nStrategy-Level Summary:\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "        print(f\"\\nFull report with 5 sheets saved to '{report_filename}'\")\n",
    "        print(f\"Total estimated cost for this run: ${costs['total_cost']:.4f}\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    create_dummy_files()\n",
    "    if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "        raise ValueError(\"OPENAI_API_KEY environment variable not set. Please create a .env file.\")\n",
    "\n",
    "    cost_tracker = CostTracker(config)\n",
    "    llm = ChatOpenAI(model=config[\"llm_model\"], temperature=0)\n",
    "    docs_df = pd.read_excel(\"document_dataset.xlsx\")\n",
    "    golden_df = pd.read_excel(\"golden_source.xlsx\")\n",
    "\n",
    "    categorizer = DocumentCategorizer(config[\"categories_1\"], config[\"categories_2\"], llm, cost_tracker)\n",
    "    categorized_df = categorizer.categorize_dataset(docs_df)\n",
    "    categorized_df.to_excel(\"document_dataset_categorized.xlsx\", index=False)\n",
    "    print(\"Categorized documents saved.\")\n",
    "\n",
    "    retriever = DocumentRetriever(categorized_df, config, cost_tracker)\n",
    "    \n",
    "    all_results = {}\n",
    "    print(\"\\nRunning retrieval strategies for all questions...\")\n",
    "    for _, row in tqdm(golden_df.iterrows(), total=len(golden_df), desc=\"Evaluating Questions\"):\n",
    "        q_id, question = row['Question_ID'], row['Question_Text']\n",
    "        cost_tracker.cost_breakdown['query_categorization'] = 0\n",
    "        \n",
    "        all_results[q_id] = {\n",
    "            s_code: {'tocs': t, 'latency': l, 'cost': c}\n",
    "            for s_code, (t, l, c) in zip(\n",
    "                ['A', 'B', 'C', 'D'],\n",
    "                [retriever.retrieve(s, question, config[\"retrieval_k\"], q_id) for s in ['A', 'B', 'C', 'D']]\n",
    "            )\n",
    "        }\n",
    "        all_results[q_id]['categorization_cost'] = cost_tracker.cost_breakdown['query_categorization']\n",
    "        if hasattr(retriever, '_cat_cache'): retriever._cat_cache.clear()\n",
    "\n",
    "    evaluator = Evaluator(golden_df, config[\"retrieval_k\"])\n",
    "    evaluator.generate_report(all_results, cost_tracker, retriever.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33becad4-77a2-4132-a2ca-a450cc58767d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcaad5d1-d665-453f-aa10-6207a5e02ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part</th>\n",
       "      <th>Title</th>\n",
       "      <th>Chapter</th>\n",
       "      <th>Section</th>\n",
       "      <th>Subsection</th>\n",
       "      <th>Part_Heading</th>\n",
       "      <th>Title_Heading</th>\n",
       "      <th>Chapter_Heading</th>\n",
       "      <th>Section_Heading</th>\n",
       "      <th>Subsection_Heading</th>\n",
       "      <th>Token_Count</th>\n",
       "      <th>Ends_With_Dot</th>\n",
       "      <th>Article_Number</th>\n",
       "      <th>Article_Heading</th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_With_Pagebreaks</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PART ONE</td>\n",
       "      <td>TITLE I</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>SUBJECT MATTER, SCOPE AND DEFINITIONS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>683</td>\n",
       "      <td>True</td>\n",
       "      <td>5a</td>\n",
       "      <td>Article 5a - Definitions specific to crypto-as...</td>\n",
       "      <td>For the purposes of this Regulation, the follo...</td>\n",
       "      <td>For the purposes of this Regulation, the follo...</td>\n",
       "      <td>Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...</td>\n",
       "      <td>[-0.005323531571775675, 0.02995140850543976, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PART ONE</td>\n",
       "      <td>TITLE II</td>\n",
       "      <td>CHAPTER 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>LEVEL OF APPLICATION OF REQUIREMENTS</td>\n",
       "      <td>Application of requirements on an individual b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>672</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "      <td>Article 6 - General principles</td>\n",
       "      <td>1. Institutions shall comply with the obligati...</td>\n",
       "      <td>1. Institutions shall comply with the obligati...</td>\n",
       "      <td>Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...</td>\n",
       "      <td>[-0.02480098232626915, 0.0840955525636673, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PART ONE</td>\n",
       "      <td>TITLE II</td>\n",
       "      <td>CHAPTER 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>LEVEL OF APPLICATION OF REQUIREMENTS</td>\n",
       "      <td>Application of requirements on an individual b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>471</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>Article 7 - Derogation from the application of...</td>\n",
       "      <td>1. Competent authorities may waive the applica...</td>\n",
       "      <td>1. Competent authorities may waive the applica...</td>\n",
       "      <td>Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...</td>\n",
       "      <td>[0.01249348558485508, 0.07407958060503006, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PART ONE</td>\n",
       "      <td>TITLE II</td>\n",
       "      <td>CHAPTER 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>LEVEL OF APPLICATION OF REQUIREMENTS</td>\n",
       "      <td>Application of requirements on an individual b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>960</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "      <td>Article 8 - Derogation from the application of...</td>\n",
       "      <td>1. The competent authorities may waive in full...</td>\n",
       "      <td>1. The competent authorities may waive in full...</td>\n",
       "      <td>Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...</td>\n",
       "      <td>[0.007952353917062283, 0.08847298473119736, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PART ONE</td>\n",
       "      <td>TITLE II</td>\n",
       "      <td>CHAPTER 1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>LEVEL OF APPLICATION OF REQUIREMENTS</td>\n",
       "      <td>Application of requirements on an individual b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>257</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>Article 9 - Individual consolidation method</td>\n",
       "      <td>1. Subject to paragraphs 2 and 3 of this Artic...</td>\n",
       "      <td>1. Subject to paragraphs 2 and 3 of this Artic...</td>\n",
       "      <td>Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...</td>\n",
       "      <td>[0.02038790099322796, 0.05491769686341286, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Part     Title    Chapter Section Subsection        Part_Heading  \\\n",
       "6   PART ONE   TITLE I                                GENERAL PROVISIONS   \n",
       "7   PART ONE  TITLE II  CHAPTER 1                     GENERAL PROVISIONS   \n",
       "8   PART ONE  TITLE II  CHAPTER 1                     GENERAL PROVISIONS   \n",
       "9   PART ONE  TITLE II  CHAPTER 1                     GENERAL PROVISIONS   \n",
       "10  PART ONE  TITLE II  CHAPTER 1                     GENERAL PROVISIONS   \n",
       "\n",
       "                            Title_Heading  \\\n",
       "6   SUBJECT MATTER, SCOPE AND DEFINITIONS   \n",
       "7    LEVEL OF APPLICATION OF REQUIREMENTS   \n",
       "8    LEVEL OF APPLICATION OF REQUIREMENTS   \n",
       "9    LEVEL OF APPLICATION OF REQUIREMENTS   \n",
       "10   LEVEL OF APPLICATION OF REQUIREMENTS   \n",
       "\n",
       "                                      Chapter_Heading Section_Heading  \\\n",
       "6                                                                       \n",
       "7   Application of requirements on an individual b...                   \n",
       "8   Application of requirements on an individual b...                   \n",
       "9   Application of requirements on an individual b...                   \n",
       "10  Application of requirements on an individual b...                   \n",
       "\n",
       "   Subsection_Heading  Token_Count  Ends_With_Dot Article_Number  \\\n",
       "6                              683           True             5a   \n",
       "7                              672           True              6   \n",
       "8                              471           True              7   \n",
       "9                              960           True              8   \n",
       "10                             257           True              9   \n",
       "\n",
       "                                      Article_Heading  \\\n",
       "6   Article 5a - Definitions specific to crypto-as...   \n",
       "7                      Article 6 - General principles   \n",
       "8   Article 7 - Derogation from the application of...   \n",
       "9   Article 8 - Derogation from the application of...   \n",
       "10        Article 9 - Individual consolidation method   \n",
       "\n",
       "                                                 Text  \\\n",
       "6   For the purposes of this Regulation, the follo...   \n",
       "7   1. Institutions shall comply with the obligati...   \n",
       "8   1. Competent authorities may waive the applica...   \n",
       "9   1. The competent authorities may waive in full...   \n",
       "10  1. Subject to paragraphs 2 and 3 of this Artic...   \n",
       "\n",
       "                                 Text_With_Pagebreaks  \\\n",
       "6   For the purposes of this Regulation, the follo...   \n",
       "7   1. Institutions shall comply with the obligati...   \n",
       "8   1. Competent authorities may waive the applica...   \n",
       "9   1. The competent authorities may waive in full...   \n",
       "10  1. Subject to paragraphs 2 and 3 of this Artic...   \n",
       "\n",
       "                                        combined_text  \\\n",
       "6   Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...   \n",
       "7   Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...   \n",
       "8   Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...   \n",
       "9   Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...   \n",
       "10  Part_Heading: GENERAL PROVISIONS\\nTitle_Headin...   \n",
       "\n",
       "                                            embedding  \n",
       "6   [-0.005323531571775675, 0.02995140850543976, 0...  \n",
       "7   [-0.02480098232626915, 0.0840955525636673, 0.0...  \n",
       "8   [0.01249348558485508, 0.07407958060503006, 0.0...  \n",
       "9   [0.007952353917062283, 0.08847298473119736, 0....  \n",
       "10  [0.02038790099322796, 0.05491769686341286, 0.0...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "docs_df = pd.read_parquet(\"data/df_with_embeddings.parquet\")\n",
    "\n",
    "docs_df[6:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b78e03d-5cc6-42b2-a4c2-fb21c939ba00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Part_Heading</th>\n",
       "      <th>Title_Heading</th>\n",
       "      <th>Chapter_Heading</th>\n",
       "      <th>Section_Heading</th>\n",
       "      <th>Subsection_Heading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>SUBJECT MATTER, SCOPE AND DEFINITIONS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>LEVEL OF APPLICATION OF REQUIREMENTS</td>\n",
       "      <td>Application of requirements on an individual b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>LEVEL OF APPLICATION OF REQUIREMENTS</td>\n",
       "      <td>Prudential consolidation</td>\n",
       "      <td>Application of requirements on a consolidated ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GENERAL PROVISIONS</td>\n",
       "      <td>LEVEL OF APPLICATION OF REQUIREMENTS</td>\n",
       "      <td>Prudential consolidation</td>\n",
       "      <td>Methods for prudential consolidation</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Part_Heading                          Title_Heading  \\\n",
       "0                                                               \n",
       "1   GENERAL PROVISIONS  SUBJECT MATTER, SCOPE AND DEFINITIONS   \n",
       "7   GENERAL PROVISIONS   LEVEL OF APPLICATION OF REQUIREMENTS   \n",
       "12  GENERAL PROVISIONS   LEVEL OF APPLICATION OF REQUIREMENTS   \n",
       "17  GENERAL PROVISIONS   LEVEL OF APPLICATION OF REQUIREMENTS   \n",
       "\n",
       "                                      Chapter_Heading  \\\n",
       "0                                                       \n",
       "1                                                       \n",
       "7   Application of requirements on an individual b...   \n",
       "12                           Prudential consolidation   \n",
       "17                           Prudential consolidation   \n",
       "\n",
       "                                      Section_Heading Subsection_Heading  \n",
       "0                                                                         \n",
       "1                                                                         \n",
       "7                                                                         \n",
       "12  Application of requirements on a consolidated ...                     \n",
       "17               Methods for prudential consolidation                     "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['Part_Heading', 'Title_Heading', 'Chapter_Heading', \n",
    "                    'Section_Heading', 'Subsection_Heading', 'Article_Heading']\n",
    "\n",
    "cols = ['Part_Heading', 'Title_Heading', 'Chapter_Heading', \n",
    "                    'Section_Heading', 'Subsection_Heading']\n",
    "\n",
    "kala = docs_df[cols].drop_duplicates()\n",
    "kala.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f963362-7b49-4a58-8780-8ed7e2cd1733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'GENERAL PROVISIONS', 'OWN FUNDS AND ELIGIBLE LIABILITIES',\n",
       "       'CAPITAL REQUIREMENTS', 'LARGE EXPOSURES', 'LIQUIDITY', 'LEVERAGE',\n",
       "       'REPORTING REQUIREMENTS', 'DISCLOSURE BY INSTITUTIONS',\n",
       "       'DELEGATED AND IMPLEMENTING ACTS',\n",
       "       'TRANSITIONAL PROVISIONS, REPORTS, REVIEWS AND AMENDMENTS',\n",
       "       'FINAL PROVISIONS'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kala['Part_Heading'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9751022f-19df-4dc6-8c9e-687a594c3756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'SUBJECT MATTER, SCOPE AND DEFINITIONS',\n",
       "       'LEVEL OF APPLICATION OF REQUIREMENTS', 'ELEMENTS OF OWN FUNDS',\n",
       "       'MINORITY INTEREST AND ADDITIONAL TIER 1 AND TIER 2 INSTRUMENTS ISSUED BY SUBSIDIARIES',\n",
       "       'QUALIFYING HOLDINGS OUTSIDE THE FINANCIAL SECTOR',\n",
       "       'GENERAL REQUIREMENTS, VALUATION AND REPORTING',\n",
       "       'CAPITAL REQUIREMENTS FOR CREDIT RISK',\n",
       "       'OWN FUNDS REQUIREMENT FOR OPERATIONAL RISK',\n",
       "       'OWN FUNDS REQUIREMENTS FOR MARKET RISK',\n",
       "       'OWN FUNDS REQUIREMENTS FOR SETTLEMENT RISK',\n",
       "       'OWN FUNDS REQUIREMENTS FOR CREDIT VALUATION ADJUSTMENT RISK',\n",
       "       'DEFINITIONS AND LIQUIDITY REQUIREMENTS', 'LIQUIDITY REPORTING',\n",
       "       'REPORTING ON STABLE FUNDING', 'THE NET STABLE FUNDING RATIO',\n",
       "       'GENERAL PRINCIPLES',\n",
       "       'TECHNICAL CRITERIA ON TRANSPARENCY AND DISCLOSURE',\n",
       "       'QUALIFYING REQUIREMENTS FOR THE USE OF PARTICULAR INSTRUMENTS OR METHODOLOGIES',\n",
       "       'TRANSITIONAL PROVISIONS', 'REPORTS AND REVIEWS',\n",
       "       'IMPLEMENTATION OF RULES', 'AMENDMENTS'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kala['Title_Heading'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bed897a-a40d-443f-bb83-1eb6bea4935b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Application of requirements on an individual basis',\n",
       "       'Prudential consolidation', 'Tier 1 capital',\n",
       "       'Common Equity Tier 1 capital', 'Additional Tier 1 capital',\n",
       "       'Tier 2 capital', 'Own funds', 'Eligible liabilities',\n",
       "       'General requirements for own funds and eligible liabilities',\n",
       "       'Required level of own funds', 'Trading book',\n",
       "       'General principles', 'Standardised approach',\n",
       "       'Internal Ratings Based Approach', 'Credit risk mitigation',\n",
       "       'Securitisation', 'Counterparty credit risk',\n",
       "       'CALCULATION OF THE OWN FUNDS REQUIREMENT FOR OPERATIONAL RISK',\n",
       "       'DATA COLLECTION AND GOVERNANCE', 'General provisions',\n",
       "       'Alternative standardised approach',\n",
       "       'Alternative internal model approach',\n",
       "       'Own funds requirements for position risk',\n",
       "       'Own funds requirements for foreign-exchange risk',\n",
       "       'Own funds requirements for commodities risk',\n",
       "       'The net stable funding ratio',\n",
       "       'General rules for the calculation of the net stable funding ratio',\n",
       "       'Available stable funding', 'Required stable funding',\n",
       "       'Derogation for small and non-complex institutions',\n",
       "       'Available stable funding for the simplified calculation of the net stable funding ratio',\n",
       "       'Required stable funding for the simplified calculation of the net stable funding ratio',\n",
       "       'Own funds requirements, unrealised gains and losses measured at fair value and deductions',\n",
       "       'Grandfathering of capital instruments',\n",
       "       'Transitional provisions for disclosure of own funds',\n",
       "       'Large exposures, own funds requirements, leverage and the Basel I Floor'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kala['Chapter_Heading'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e1089d7-3d9f-4560-8f8f-c77af5b1ac56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', 'Application of requirements on a consolidated basis',\n",
       "       'Methods for prudential consolidation',\n",
       "       'Scope of prudential consolidation',\n",
       "       'Common Equity Tier 1 items and instruments', 'Prudential filters',\n",
       "       'Deductions from Common Equity Tier 1 items, exemptions and alternatives',\n",
       "       'Common Equity Tier 1 capital',\n",
       "       'Additional Tier 1 items and instruments',\n",
       "       'Deductions from Additional Tier 1 items',\n",
       "       'Additional Tier 1 capital', 'Tier 2 items and instruments',\n",
       "       'Deductions from Tier 2 items', 'Tier 2 capital',\n",
       "       'Eligible liabilities items and instruments',\n",
       "       'Deductions from eligible liabilities items',\n",
       "       'Own funds and eligible liabilities',\n",
       "       'Own funds requirements for institutions',\n",
       "       'Own funds requirements for investment firms with limited authorisation to provide investment services',\n",
       "       'General principles', 'Risk weights',\n",
       "       'Recognition and mapping of credit risk assessment',\n",
       "       'Use of the ECAI credit assessments for the determination of risk weights',\n",
       "       'Permission by competent authorities to use the IRB approach',\n",
       "       'Calculation of risk-weighted exposure amounts',\n",
       "       'Expected loss amounts', 'PD, LGD and maturity', 'Exposure value',\n",
       "       'Requirements for the IRB approach',\n",
       "       'Definitions and general requirements',\n",
       "       'Eligible forms of credit risk mitigation', 'Requirements',\n",
       "       'Calculating the effects of credit risk mitigation',\n",
       "       'Maturity mismatches',\n",
       "       'Definitions and criteria for simple, transparent and standardised securitisations',\n",
       "       'Recognition of significant risk transfer',\n",
       "       'External credit assessments', 'Definitions',\n",
       "       'Methods for calculating the exposure value',\n",
       "       'Standardised approach for counterparty credit risk',\n",
       "       'Simplified standardised approach for counterparty credit risk',\n",
       "       'Original exposure method', 'Internal Model Method',\n",
       "       'Contractual netting', 'Items in the trading book',\n",
       "       'Own funds requirements for exposures to a central counterparty',\n",
       "       'General provisions',\n",
       "       'Sensitivities-based method for calculating the own funds requirement',\n",
       "       'Risk factor and sensitivity definitions',\n",
       "       'The residual risk add-on',\n",
       "       'Own funds requirements for the default risk',\n",
       "       'Risk weights and correlations',\n",
       "       'Permission and own funds requirements', 'General requirements',\n",
       "       'Internal default risk model',\n",
       "       'General provisions and specific instruments', 'Debt instruments',\n",
       "       'Equities', 'Underwriting',\n",
       "       'Specific risk own funds requirements for positions hedged by credit derivatives',\n",
       "       'Own funds requirements for CIUs',\n",
       "       'Available stable funding factors',\n",
       "       'Required stable funding factors', 'Own funds requirements',\n",
       "       'Unrealised gains and losses measured at fair value', 'Deductions',\n",
       "       'minority interest and additional Tier 1 and Tier 2 instruments issued by subsidiaries',\n",
       "       'Additional filters and deductions',\n",
       "       'Instruments constituting State aid',\n",
       "       'Instruments not constituting State aid'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kala['Section_Heading'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1bef238-b0d0-4913-b894-5a9f2c106faa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chapter_Heading\n",
       "                                                                                             186\n",
       "Counterparty credit risk                                                                      53\n",
       "Alternative standardised approach                                                             49\n",
       "Credit risk mitigation                                                                        48\n",
       "Internal Ratings Based Approach                                                               45\n",
       "Standardised approach                                                                         37\n",
       "Securitisation                                                                                35\n",
       "Common Equity Tier 1 capital                                                                  28\n",
       "Large exposures, own funds requirements, leverage and the Basel I Floor                       26\n",
       "Own funds requirements for position risk                                                      25\n",
       "Own funds requirements, unrealised gains and losses measured at fair value and deductions     20\n",
       "Required stable funding                                                                       19\n",
       "Alternative internal model approach                                                           17\n",
       "Prudential consolidation                                                                      12\n",
       "Eligible liabilities                                                                          12\n",
       "Additional Tier 1 capital                                                                     11\n",
       "Required stable funding for the simplified calculation of the net stable funding ratio        10\n",
       "General requirements for own funds and eligible liabilities                                   10\n",
       "Tier 2 capital                                                                                10\n",
       "DATA COLLECTION AND GOVERNANCE                                                                 9\n",
       "Required level of own funds                                                                    9\n",
       "Grandfathering of capital instruments                                                          9\n",
       "Trading book                                                                                   8\n",
       "Own funds requirements for commodities risk                                                    7\n",
       "Available stable funding for the simplified calculation of the net stable funding ratio        7\n",
       "Available stable funding                                                                       7\n",
       "General rules for the calculation of the net stable funding ratio                              6\n",
       "General principles                                                                             5\n",
       "Application of requirements on an individual basis                                             5\n",
       "CALCULATION OF THE OWN FUNDS REQUIREMENT FOR OPERATIONAL RISK                                  5\n",
       "Own funds requirements for foreign-exchange risk                                               4\n",
       "General provisions                                                                             3\n",
       "The net stable funding ratio                                                                   2\n",
       "Tier 1 capital                                                                                 1\n",
       "Own funds                                                                                      1\n",
       "Derogation for small and non-complex institutions                                              1\n",
       "Transitional provisions for disclosure of own funds                                            1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['Chapter_Heading'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05328cd3-3acb-4150-8b03-e2feae08e9a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title_Heading\n",
       "CAPITAL REQUIREMENTS FOR CREDIT RISK                                                     223\n",
       "OWN FUNDS REQUIREMENTS FOR MARKET RISK                                                   105\n",
       "ELEMENTS OF OWN FUNDS                                                                     73\n",
       "TRANSITIONAL PROVISIONS                                                                   56\n",
       "THE NET STABLE FUNDING RATIO                                                              52\n",
       "                                                                                          39\n",
       "OWN FUNDS REQUIREMENTS FOR CREDIT VALUATION ADJUSTMENT RISK                               32\n",
       "REPORTS AND REVIEWS                                                                       32\n",
       "TECHNICAL CRITERIA ON TRANSPARENCY AND DISCLOSURE                                         23\n",
       "LEVEL OF APPLICATION OF REQUIREMENTS                                                      17\n",
       "GENERAL REQUIREMENTS, VALUATION AND REPORTING                                             17\n",
       "OWN FUNDS REQUIREMENT FOR OPERATIONAL RISK                                                14\n",
       "LIQUIDITY REPORTING                                                                       12\n",
       "MINORITY INTEREST AND ADDITIONAL TIER 1 AND TIER 2 INSTRUMENTS ISSUED BY SUBSIDIARIES     10\n",
       "GENERAL PRINCIPLES                                                                        10\n",
       "SUBJECT MATTER, SCOPE AND DEFINITIONS                                                      6\n",
       "IMPLEMENTATION OF RULES                                                                    4\n",
       "DEFINITIONS AND LIQUIDITY REQUIREMENTS                                                     4\n",
       "QUALIFYING REQUIREMENTS FOR THE USE OF PARTICULAR INSTRUMENTS OR METHODOLOGIES             4\n",
       "QUALIFYING HOLDINGS OUTSIDE THE FINANCIAL SECTOR                                           3\n",
       "OWN FUNDS REQUIREMENTS FOR SETTLEMENT RISK                                                 3\n",
       "REPORTING ON STABLE FUNDING                                                                2\n",
       "AMENDMENTS                                                                                 2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['Title_Heading'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22a8864e-84f6-461e-a88a-9a42e897d928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Section_Heading\n",
       "                                                                           280\n",
       "Calculation of risk-weighted exposure amounts                               32\n",
       "Risk weights                                                                27\n",
       "Required stable funding factors                                             25\n",
       "Risk weights and correlations                                               21\n",
       "Requirements for the IRB approach                                           20\n",
       "Calculating the effects of credit risk mitigation                           20\n",
       "Deductions from Common Equity Tier 1 items, exemptions and alternatives     17\n",
       "Standardised approach for counterparty credit risk                          17\n",
       "Deductions                                                                  13\n",
       "Internal Model Method                                                       12\n",
       "Requirements                                                                12\n",
       "Own funds requirements for exposures to a central counterparty              12\n",
       "Available stable funding factors                                            10\n",
       "Eligible forms of credit risk mitigation                                    10\n",
       "General requirements                                                        10\n",
       "General provisions                                                           9\n",
       "Permission by competent authorities to use the IRB approach                  9\n",
       "Risk factor and sensitivity definitions                                      9\n",
       "Own funds requirements for the default risk                                  9\n",
       "Instruments not constituting State aid                                       8\n",
       "Sensitivities-based method for calculating the own funds requirement         8\n",
       "General provisions and specific instruments                                  8\n",
       "Debt instruments                                                             7\n",
       "PD, LGD and maturity                                                         6\n",
       "Common Equity Tier 1 items and instruments                                   6\n",
       "Scope of prudential consolidation                                            6\n",
       "Deductions from eligible liabilities items                                   6\n",
       "Application of requirements on a consolidated basis                          5\n",
       "Internal default risk model                                                  5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_df['Section_Heading'].value_counts().head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c33579-9afb-4198-8f61-296cb165b5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
